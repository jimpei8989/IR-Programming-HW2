# Web Retrieval & Web Mining<br>Programming HW2

###### By: Wu-Jun Pei (B06902029)

## Definition / Settings

#### Platform

- Python 3.8.2
- torch==1.5.0
- numpy==1.18.4

#### Common

- $M_I$ï¼šinteraction matrixã€‚ç¶­åº¦æ˜¯ $(N, M)$ï¼Œå…¶ä¸­ $N$ æ˜¯ user æ•¸é‡ã€$M$ æ˜¯ item æ•¸é‡ã€‚åœ¨é€™å€‹ task ä¸­ $N = 4454$ã€$M = 3260$ã€‚
- $\mathbf u_i$ï¼šuser vectorã€‚user $i$ æœ‰èˆ‡å“ªäº› item äº’å‹•éçš„ binary vectorï¼Œå³ç‚º $M_I$ çš„ç¬¬ $i$ å€‹ rowã€‚$\tilde {\mathbf u}_i$ ç‚º $\mathbf u_i$ é matrix factorization çš„ $F$ ç‚º embedded vectorã€‚
- $\mathbf i_j$ï¼šitem vectorã€‚item $j$ æœ‰èˆ‡å“ªäº› user äº’å‹•éçš„ binary vectorï¼Œå³ç‚º $M_I$ çš„ç¬¬ $j$ å€‹ columnã€‚$\tilde {\mathbf i}_j$ ç‚º $\mathbf i_j$ é matrix factorization çš„ $F$ ç‚º embedded vectorã€‚

#### Matrix Factorization

- Weight æ˜¯ä¸€å€‹ $(K, F)$ çš„çŸ©é™£ï¼Œä¸€é–‹å§‹å¾ $\mathcal N(0, 1)$ ç”¢ç”Ÿè€Œæˆã€‚
- input ä¸€å€‹ user / item vectorï¼Œoutput ä¸€å€‹ $F$ ç¶­çš„ embedded vectorã€‚

#### Data Processing

<u>***Negative Sampling***</u>

æ¡å–ä»¥ä¸‹å…©ç¨®æ–¹å¼ï¼š

1. `fixed`ï¼šå›ºå®šé¸å–ä¸€å®šæ•¸é‡çš„ uninteracted items ä½œç‚º negative examplesã€‚
2. `sample`ï¼šå°‡å‰©é¤˜çš„æ‰€æœ‰çš„ uninteracted items ä½œç‚º negative examplesã€‚

<u>***Train / Validation Split***</u> 

- å›ºå®šé¸å– 0.8 çš„ positive / negative example ä½œç‚º training dataï¼Œå‰©ä¸‹ 0.2 ä½œç‚º validation dataã€‚

## Â§ Q1

> Describe your MF with BCE (e.g. parameters, loss function, negative sample method and MAP score on Kaggle public scoreboard)

#### Dataset

- è‹¥ç‚º `fixed`<br>å°‡æ‰€æœ‰ positive / negative example ç•¶ä½œ dataset ä¸‹å» trainã€‚
- è‹¥ç‚º `sample`
    1. æ±ºå®š $r = \frac{\text{#negative}}{\text{#positive}}$
    2. ä¸€å€‹ epoch ç¸½å…±é¸å–æ‰€æœ‰çš„ positive example ä»¥åŠ sample $(r \cdot \text{#positive})$ å€‹ negative examplesã€‚

å¾Œä¾†çš†ä½¿ç”¨ `fixed`ï¼Œå› ç‚º `sample` æœƒç„¡æ³• train èµ·ä¾†......

#### Loss Function

$$
BCELoss = \sum_{(u, i, y) \in \mathcal D} -[y \log (\tilde{\mathbf u}_u^T \tilde{\mathbf i}_i) + (1 - y) \log (1 - \tilde{\mathbf u}_u^T \tilde{\mathbf i}_i)]
$$

#### Model Parameters

- Latent Dimension $F$: **<u>128</u>**
- Gradient Descent Optimizer: **<u>Adam</u>**
    - Learning rate: <u>**5e-3**</u>
    - Weight decay (l2 regularization): **<u>1e-5</u>**
    - Learning rate scheduler: <u>**ReduceLROnPlateau**</u>
- \#Epochs: <u>**100**</u> (å¤§æ¦‚ 70 å€‹ epoch å°±æ”¶æ–‚äº†)

#### Result

|        Model         | MF-BCE-128 |
| :------------------: | :--------: |
|    Validation MAP    |  0.12756   |
| Kaggle Public Score  |  0.03991   |
| Kaggle Private Score |  0.03971   |

##### *Reference*

- [PyTorch - Binary Cross Entropy](https://pytorch.org/docs/stable/nn.html#bceloss)

## Â§ Q2

> Describe your MF with BPR (e.g.parameters, loss function, negative sample method and MAP score on Kaggle public scoreboard)

#### Dataset

å› ç‚º BPR è¦é¸å–æ‰€æœ‰ userã€è©² user çš„ positive exampleã€negative exampleã€‚å¦‚æœåªè€ƒæ…®åŸå§‹çš„ `train.csv` çš„è©±ï¼Œç¸½å…±æœƒæœ‰ <u>**977,680,643**</u> ç­†è³‡æ–™ï¼Œè¦å…¨éƒ¨è·‘å®Œå¯¦åœ¨æ˜¯ä¸å¤ªå¯èƒ½ã€‚å› æ­¤ï¼Œæˆ‘æ¡ç”¨çš„æ–¹æ³•æ˜¯ï¼š

- Uniformly sample $(user, pos)$ çš„ exampleï¼Œä¹‹å¾Œåœ¨å¾è©² user çš„ negative items ä¸­ uniformly sample ä¸€å€‹ $neg$ã€‚
- æ¯å€‹ epoch sample å…¶ä¸­ **<u>1,000,000</u>** ç­† $(user, pos, neg)$ã€‚

#### Loss Function

$$
BPRLoss = \sum_{(u, p, n) \in \mathcal D} \log(2 - \sigma(\tilde{\mathbf u}_u^T \mathbf i_p - \tilde{\mathbf u}_u^T \mathbf i_n))
$$

æˆ‘ç™¼ç¾åŠ©æ•™æŠ•å½±ç‰‡ä¸Šé¢çš„ loss function æ˜¯éŒ¯èª¤çš„ï¼Œå› ç‚º positive çš„åˆ†æ•¸å’Œ negative çš„åˆ†æ•¸å°±æ˜¯è¦è¶Šå¤§è¶Šå¥½ï¼Œè€Œ sigmoid å’Œ log éƒ½æ˜¯éå¢çš„å‡½æ•¸ï¼Œæ‰€ä»¥è¦åŠ ä¸Šè² è™Ÿæ‰èƒ½ gradient descentã€‚åŠ ä¸Š 2 æ˜¯ç‚ºäº†è®“ log çš„å®šç¾©åŸŸåœ¨ $(1, 2)$ ä¹‹é–“ï¼Œé€™æ¨£ loss éƒ½æœƒæ˜¯æ­£çš„ã€è¶Šé è¿‘ 0 è¶Šå¥½ï¼Œæ–¹ä¾¿è§€å¯Ÿçµæœã€‚

#### Model Parameters

- Latent Dimension $F$: **<u>64</u>**
- Gradient Descent Optimizer: **<u>Adam</u>**
    - Learning rate: <u>**1e-3**</u>
    - Weight decay (l2 regularization): **<u>1e-4</u>**
    - Learning Rate Scheduler: <u>**ReduceLROnPlateau**</u>

### Result

|        Model         | MF-MPR-64 |
| :------------------: | :-------: |
|    Validation MAP    |  0.34533  |
| Kaggle Public Score  |  0.05692  |
| Kaggle Private Score |  0.05331  |

##### <u>*Reference*</u>

- [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/pdf/1205.2618.pdf)

## Â§ Q3

> Compare your results of Q1 and Q2. Do you think the BPR loss benefits the performance? If do, write some reasons of why BPR works well; If not, write some reasons of why BPR fails.

æˆ‘èªç‚º BPR å°æ–¼ MAP çš„å¹«åŠ©å¾ˆå¤§ï¼Œå› ç‚º BCE åªæœ‰çœ‹ä¸€å€‹ $(user, item)$ é€™æ¨£çš„ pair æ˜¯ä¸æ˜¯ positive (æœ‰ interacted)ï¼Œé€™æ¨£æœ‰é»æŠŠæ¯å€‹ä¸åŒçš„ item ç•¶æˆç¨ç«‹çš„ç‰©å“ï¼Œä¸¦å¹«ä»–å€‘è©•ä¸€å€‹ã€Œåˆ†æ•¸ã€ï¼Œä½†é‚£å€‹åˆ†æ•¸å¯èƒ½ä¸¦æ²’æœ‰é‚£éº¼æœ‰æ„ç¾©ã€‚ç›¸è¼ƒæ–¼ BCEï¼ŒBPR æ›´é—œæ³¨åœ¨å…©å€‹ç‰©å“çš„ã€Œæ¯”è¼ƒã€ï¼Œå› æ­¤ä»–çš„æ’ååšå¾—æ¯”è¼ƒå¥½ä¹Ÿæ˜¯æƒ…æœ‰å¯åŸçš„ï¼

æˆ‘è¦ºå¾—æˆ‘ç›®å‰çš„ loss function ä¸¦æ²’æœ‰è¨‚å¾—å¾ˆå¥½ï¼Œå¾Œä¾†æœ‰æƒ³åˆ°ä¸€å€‹èˆ‡ BCE æ¯”è¼ƒåƒçš„ loss function æœ‰ä¸€æ¨£çš„åŠŸç”¨ï¼š
$$
BPRLoss' = \sum_{(u, p, n) \in \mathcal D} -\log(\sigma(\tilde{\mathbf u}_u^T \mathbf i_p - \tilde{\mathbf u}_u^T \mathbf i_n))
$$
é€™å€‹ loss function å…¶å¯¦å°±æ˜¯ BCE æŠŠ y æ°¸é è¨­æˆ 1 çš„ç‰ˆæœ¬ï¼ˆé‚è¼¯ä¸Šä¾†èªªä¹Ÿèªªå¾—é€šï¼Œå› ç‚ºè¦è®“åˆ†æ•¸æ‹‰è¶Šé–‹è¶Šå¥½ï¼Œå³ sigmoid å¾Œè¶Šæ¥è¿‘ 1 è¶Šå¥½ï¼‰ã€‚ä»–æœ‰ä¸€å€‹å¾ˆå¥½çš„æ€§è³ªï¼å‡¹å‘ä¸Šï¼Œåœ¨åš gradient descent æ™‚æ‡‰è©²æœƒæœ‰æ¯”è¼ƒå¥½çš„è¡¨ç¾ã€‚ç„¶è€Œå› ç‚ºæ™‚é–“çš„å› ç´ æˆ‘æ²’æœ‰è¾¦æ³•æ™‚åšå‡ºé€™å€‹ç‰ˆæœ¬ä¸¦æ¯”è¼ƒå·®ç•° QQ

![](Report/Prob3.png)

## Â§ Q4

> Plot the MAP curve on testing data (Kaggle) for hidden factors ğ‘‘ = 16, 32, 64, 128 and describe your finding.

#### BCE

ä½¿ç”¨å’Œä¸Šé¢ä¸€æ¨£çš„åƒæ•¸ï¼Œåªæœ‰æ”¹è®Š latent dimensionã€‚

#### BPR

ä½¿ç”¨å’Œä¸Šé¢ä¸€æ¨£çš„åƒæ•¸ï¼Œåªæœ‰æ”¹è®Š latent dimensionã€‚

#### Result

![](Report/Prob4.png)

##### Findings

- **BCE**<br>åœ¨åŒæ¨£çš„åƒæ•¸ä¸‹ï¼Œ16 ç¶­è¡¨ç¾å¾—çœŸçš„å·®è »å¤šçš„ï¼Œè€Œæ•´é«”çš„èµ°å‹¢æœ‰è¶Šä¾†è¶Šå¥½çš„è¶¨å‹¢ï¼Œæˆ–è¨± BCE é€™æ¨£çš„ Model æœ‰æ›´å¤šçš„ latent dimension å¯ä»¥è¡¨ç¾å¾—å†æ›´å¥½ä¸€é»ã€‚
- **BPR**<br>åœ¨åŒæ¨£çš„åƒæ•¸ä¸‹ï¼Œå¤§æ¦‚ 64 ç¶­çš„è¡¨ç¾æœ€å¥½ï¼Œå¯èƒ½æ˜¯å› ç‚º 16 / 32 ç¶­çš„ latent dimension ä¸å¤ å¤šï¼Œå°è‡´ underfitting çš„æƒ…å½¢ï¼Œè€Œ 128 / 256 ç‚ºç”šè‡³æ›´å¤šç¶­çš„æ™‚å€™éæ–¼ overfittingï¼Œæˆ–è¨±èª¿æ•´ l2 regularization ç­‰å…¶ä»–åƒæ•¸å¯ä»¥æ”¹å–„ä¹Ÿèªªä¸å®šã€‚

## Â§ Q5

> Change the ratio between positive and negative pairs, compare the results and discuss your finding. (Bonus 10%)

å› ç‚º BPR çš„ dataset æ˜¯ä½¿ç”¨ sample çš„æ–¹å¼è·‘çš„ï¼Œæ‰€ä»¥é€™é‚Šåªåš BCE çš„ä¸åŒ negative sampling çš„æ¯”ä¾‹ã€‚

#### Sampling æ–¹æ³•

- é¸å–æ‰€æœ‰çš„ positive exampleï¼Œä¾ç…§æ¯”ä¾‹æ±ºå®š negative example çš„æ•¸é‡ä¸¦ sampleã€‚
- é€™æ¨£å¯èƒ½æœƒå°è‡´æ¯å€‹ä¸åŒæ¯”ä¾‹çš„ dataset å¤§å°ä¸ä¸€ã€‚

#### Result

| Pos : Neg | Training Accu.<br>at last epoch | Validation Accu.<br/>at last epoch | Validation MAP | Kaggle Public MAP | Kaggle Private MAP |
| :-------: | :-----------------------------: | :--------------------------------: | :------------: | :---------------: | :----------------: |
| 1 : 0.25  |             0.8957              |               0.8711               |    0.09975     |      0.03580      |      0.03532       |
|  1 : 0.5  |             0.8530              |               0.8418               |    0.11654     |      0.03895      |      0.03999       |
|   1 : 1   |             0.8533              |               0.8360               |    0.12916     |      0.04077      |      0.04121       |
|   1 : 2   |             0.8682              |               0.8454               |    0.13254     |      0.04143      |      0.04118       |
|   1 : 4   |             0.8729              |               0.8663               |    0.13403     |      0.04033      |      0.04119       |

##### Findings

- åœ¨ 1 : 1 çš„æƒ…å½¢æ™‚ï¼Œvalidation accuracy æ˜¯æœ€ä½çš„ï¼›è€Œåœ¨æ¯”ä¾‹æ¯”è¼ƒæ‡¸æ®Šæ™‚ï¼Œvalidation accuracy åè€Œæ˜¯æ¯”è¼ƒé«˜çš„ã€‚é€™å€‹åŸå› å¯èƒ½æ˜¯å› ç‚º dataset çš„æŸå€‹ label æ•¸é‡éå¤šï¼Œè€Œå°è‡´ model å‚¾å‘å›ç­”é‚£å€‹ labelï¼Œæ­¤æ™‚ accuracy è‡ªç„¶å°±æœƒé«˜ã€‚
- å¯ä»¥ç™¼ç¾ validation MAP çš„è¡¨ç¾æ˜¯å¾ä¸Šè€Œä¸‹å–®èª¿éå¢ã€‚æˆ‘è¦ºå¾—å¯èƒ½çš„åŸå› æ˜¯å› ç‚ºçœ‹éæ¯”è¼ƒå¤š negative example çš„ model å¯ä»¥å­¸åˆ°æ¯”è¼ƒå¤šçš„è³‡è¨Šã€‚ä¸”é€™å€‹ ranking çš„ task åªéœ€è¦å€åˆ†å‰ 50 åçš„å…ˆå¾Œé †åºï¼Œä¸åƒä¸€èˆ¬çš„ classification å•é¡Œï¼Œå°±ç®—å¤§å®¶çš„åˆ†æ•¸æ™®é â‰¤ 0.5 ä¹Ÿæ²’æœ‰é—œä¿‚ï¼Œæ’å‡ºåæ¬¡ä¾†å°±å¯ä»¥æœ‰æ¯”è¼ƒå¥½çš„è¡¨ç¾ã€‚

